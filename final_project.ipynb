{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13599ebf",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Part 1: Data Collection \n",
    "\n",
    "The early youth of a child is a developmental time where students are learning how to perform many tasks and learn skills, both book smart and street smart, that can help them in life. One of those skills that begins to develop in a young age is literacy in basic math and reading, as the majority of math that one deals with in adulthood is taught in middle school (get reference), and reading comprehension is key to understanding the majority of events that happen in an adults life - understanding forms, learning new information, searching for housing, etc. Therefore, it is important that all children in this developmental stage have equitable opportunities deserving of them that in such a key growth period, they all have the tools and education necessary to learn such important and long lasting skills such as math and reading comprehension.\n",
    "\n",
    "However, not all students are given such equally fitted opportunities. The US education system has long been known to have varying standards of education (GET REFERENCE), where differences in education quality begin as early as pre-kindergarten, but not a lot of documentation has been procured to confirm on any large variation in education quality. It is imperative that if these differences in education quality exist, then they be resolved on an institutional level. \n",
    "\n",
    "So, our focus of project is to confirm if education inequality is reflected by national math and reading examination differences and recognize factors such as race or gender or state that may play significant roles in such (if they exist), and use such analysis to predict how future years education inequality will be if the current education system/institution is maintained. \n",
    "\n",
    "Our null hypothesis will be that race, gender, and state do not have any relationship or impact on math or reading literacy in children in developmental stages. Our alternative hypothesis will be that race, gender, and state have some relationship or impact on math or reading literacy in children in developmental stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29add4e5",
   "metadata": {},
   "source": [
    "## Part 2: Data Management/Representation\n",
    "\n",
    "First we have to import the necessary libraries that we need to load the dataset. We are using pandas, numpy, and matplotlib.pyplot. Pandas is used for the DataFrame object since that is an easy way to store tabular data. Numpy is used for its math functionality and mathplotlib.pyplot is used to plot graphs demonstrating relationships between variables in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99c2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67154b1",
   "metadata": {},
   "source": [
    "Now we have to load the data. The data is stored in the \"states_all_extended.csv\" file and so we have to load it into a DataFrame. This can be done using pandas \"read_csv\" method. We will store this data in a variable called \"school_data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71792d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>G08_HI_A_READING</th>\n",
       "      <th>G08_HI_A_MATHEMATICS</th>\n",
       "      <th>G08_AS_A_READING</th>\n",
       "      <th>G08_AS_A_MATHEMATICS</th>\n",
       "      <th>G08_AM_A_READING</th>\n",
       "      <th>G08_AM_A_MATHEMATICS</th>\n",
       "      <th>G08_HP_A_READING</th>\n",
       "      <th>G08_HP_A_MATHEMATICS</th>\n",
       "      <th>G08_TR_A_READING</th>\n",
       "      <th>G08_TR_A_MATHEMATICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "   ...  G08_HI_A_READING  G08_HI_A_MATHEMATICS  G08_AS_A_READING  \\\n",
       "0  ...               NaN                   NaN               NaN   \n",
       "1  ...               NaN                   NaN               NaN   \n",
       "2  ...               NaN                   NaN               NaN   \n",
       "3  ...               NaN                   NaN               NaN   \n",
       "4  ...               NaN                   NaN               NaN   \n",
       "\n",
       "   G08_AS_A_MATHEMATICS  G08_AM_A_READING  G08_AM_A_MATHEMATICS  \\\n",
       "0                   NaN               NaN                   NaN   \n",
       "1                   NaN               NaN                   NaN   \n",
       "2                   NaN               NaN                   NaN   \n",
       "3                   NaN               NaN                   NaN   \n",
       "4                   NaN               NaN                   NaN   \n",
       "\n",
       "   G08_HP_A_READING  G08_HP_A_MATHEMATICS  G08_TR_A_READING  \\\n",
       "0               NaN                   NaN               NaN   \n",
       "1               NaN                   NaN               NaN   \n",
       "2               NaN                   NaN               NaN   \n",
       "3               NaN                   NaN               NaN   \n",
       "4               NaN                   NaN               NaN   \n",
       "\n",
       "   G08_TR_A_MATHEMATICS  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_data = pd.read_csv(\"states_all_extended.csv\")\n",
    "\n",
    "school_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79c4db",
   "metadata": {},
   "source": [
    "Looking at the data, we can see that there are a few columns we will not need. For example PRIMARY_KEY isn't a data point we need to consider when testing our hypothesis so we can get rid of it. We can use the DataFrame method drop and specify the columns we want to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7658f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = school_data.drop(columns=['PRIMARY_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272c1f7",
   "metadata": {},
   "source": [
    "We should get rid of all the rows that have any kind of missing data in them since we do not want to use those data points if anything is missing. The built in method dropna can help us here since it will drop all rows with any value NaN in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a02413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193 rows were dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>G08_HI_A_READING</th>\n",
       "      <th>G08_HI_A_MATHEMATICS</th>\n",
       "      <th>G08_AS_A_READING</th>\n",
       "      <th>G08_AS_A_MATHEMATICS</th>\n",
       "      <th>G08_AM_A_READING</th>\n",
       "      <th>G08_AM_A_MATHEMATICS</th>\n",
       "      <th>G08_HP_A_READING</th>\n",
       "      <th>G08_HP_A_MATHEMATICS</th>\n",
       "      <th>G08_TR_A_READING</th>\n",
       "      <th>G08_TR_A_MATHEMATICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2009</td>\n",
       "      <td>745668.0</td>\n",
       "      <td>7186390.0</td>\n",
       "      <td>728795.0</td>\n",
       "      <td>4161103.0</td>\n",
       "      <td>2296492.0</td>\n",
       "      <td>7815467.0</td>\n",
       "      <td>3836398.0</td>\n",
       "      <td>2331552.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2009</td>\n",
       "      <td>130236.0</td>\n",
       "      <td>2158970.0</td>\n",
       "      <td>312667.0</td>\n",
       "      <td>1357747.0</td>\n",
       "      <td>488556.0</td>\n",
       "      <td>2396412.0</td>\n",
       "      <td>1129756.0</td>\n",
       "      <td>832783.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2009</td>\n",
       "      <td>981303.0</td>\n",
       "      <td>8802515.0</td>\n",
       "      <td>1044140.0</td>\n",
       "      <td>3806064.0</td>\n",
       "      <td>3952311.0</td>\n",
       "      <td>9580393.0</td>\n",
       "      <td>4296503.0</td>\n",
       "      <td>2983729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2009</td>\n",
       "      <td>474423.0</td>\n",
       "      <td>4753142.0</td>\n",
       "      <td>534510.0</td>\n",
       "      <td>3530487.0</td>\n",
       "      <td>688145.0</td>\n",
       "      <td>5017352.0</td>\n",
       "      <td>2417974.0</td>\n",
       "      <td>1492691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2009</td>\n",
       "      <td>6234155.0</td>\n",
       "      <td>73958896.0</td>\n",
       "      <td>9745250.0</td>\n",
       "      <td>40084244.0</td>\n",
       "      <td>24129402.0</td>\n",
       "      <td>74766086.0</td>\n",
       "      <td>35617964.0</td>\n",
       "      <td>21693675.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE  YEAR     ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "867     ALABAMA  2009   745668.0      7186390.0         728795.0   \n",
       "868      ALASKA  2009   130236.0      2158970.0         312667.0   \n",
       "869     ARIZONA  2009   981303.0      8802515.0        1044140.0   \n",
       "870    ARKANSAS  2009   474423.0      4753142.0         534510.0   \n",
       "871  CALIFORNIA  2009  6234155.0     73958896.0        9745250.0   \n",
       "\n",
       "     STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "867      4161103.0      2296492.0          7815467.0                3836398.0   \n",
       "868      1357747.0       488556.0          2396412.0                1129756.0   \n",
       "869      3806064.0      3952311.0          9580393.0                4296503.0   \n",
       "870      3530487.0       688145.0          5017352.0                2417974.0   \n",
       "871     40084244.0     24129402.0         74766086.0               35617964.0   \n",
       "\n",
       "     SUPPORT_SERVICES_EXPENDITURE  ...  G08_HI_A_READING  \\\n",
       "867                     2331552.0  ...               NaN   \n",
       "868                      832783.0  ...               NaN   \n",
       "869                     2983729.0  ...               NaN   \n",
       "870                     1492691.0  ...               NaN   \n",
       "871                    21693675.0  ...               NaN   \n",
       "\n",
       "     G08_HI_A_MATHEMATICS  G08_AS_A_READING  G08_AS_A_MATHEMATICS  \\\n",
       "867                   NaN               NaN                   NaN   \n",
       "868                   NaN               NaN                   NaN   \n",
       "869                   NaN               NaN                   NaN   \n",
       "870                   NaN               NaN                   NaN   \n",
       "871                   NaN               NaN                   NaN   \n",
       "\n",
       "     G08_AM_A_READING  G08_AM_A_MATHEMATICS  G08_HP_A_READING  \\\n",
       "867               NaN                   NaN               NaN   \n",
       "868               NaN                   NaN               NaN   \n",
       "869               NaN                   NaN               NaN   \n",
       "870               NaN                   NaN               NaN   \n",
       "871               NaN                   NaN               NaN   \n",
       "\n",
       "     G08_HP_A_MATHEMATICS  G08_TR_A_READING  G08_TR_A_MATHEMATICS  \n",
       "867                   NaN               NaN                   NaN  \n",
       "868                   NaN               NaN                   NaN  \n",
       "869                   NaN               NaN                   NaN  \n",
       "870                   NaN               NaN                   NaN  \n",
       "871                   NaN               NaN                   NaN  \n",
       "\n",
       "[5 rows x 265 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_rows = len(school_data.index)\n",
    "school_data = school_data[school_data['YEAR'] >= 2009]\n",
    "curr_rows = len(school_data.index)\n",
    "\n",
    "print(str(prev_rows - curr_rows) + \" rows were dropped.\")\n",
    "\n",
    "school_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a6711c",
   "metadata": {},
   "source": [
    "Since the columns names are a little tricky to figure out, we are going to outline how to read them here. \n",
    "\n",
    "G## - This signifies which grade this value is talking about; for example G04 is referring to grade 4.\n",
    "\n",
    "G##\\_A\\_A - This refers to all the students in that grade from all races.\n",
    "\n",
    "G##\\_x\\_g - This is read as the number of students of race _x_ and gender _g_ in grade ##; for example G06_AS_M is all asian male students in grade 6.\n",
    "\n",
    "G##\\_x\\_g\\_test - This is average _test_ score of race _x_ and gender _g_ in grade ##; for example G06_AS_A_MATH is the average math score of all asian students in grade 6.\n",
    "\n",
    "A in place of a gender or race signifies all genders or all races.\n",
    "\n",
    "The different race codes are AM - American Indian or Alaska Native, AS - Asian, HI - Hispanic/Latino, BL - Black, WH - White, HP - Hawaiian Native/Pacific Islander and TR - two or more races."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f7278",
   "metadata": {},
   "source": [
    "## Part 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c16c53",
   "metadata": {},
   "source": [
    "### Test Score Growth per State Prediction\n",
    "\n",
    "One of the predictive models we are creating is predicting the change in average test scores in Grade 4 based on previous years data for each state. First we are going to remove all the columns except for state, and the average test scores for math and reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0060510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>G04_A_A_READING</th>\n",
       "      <th>G04_A_A_MATHEMATICS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2009</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2009</td>\n",
       "      <td>211.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2009</td>\n",
       "      <td>210.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2009</td>\n",
       "      <td>216.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2009</td>\n",
       "      <td>210.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE  YEAR  G04_A_A_READING  G04_A_A_MATHEMATICS\n",
       "867     ALABAMA  2009            216.0                228.0\n",
       "868      ALASKA  2009            211.0                237.0\n",
       "869     ARIZONA  2009            210.0                230.0\n",
       "870    ARKANSAS  2009            216.0                238.0\n",
       "871  CALIFORNIA  2009            210.0                232.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_avg = school_data[['STATE', 'YEAR', 'G04_A_A_READING', 'G04_A_A_MATHEMATICS']]\n",
    "\n",
    "state_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba9e1d",
   "metadata": {},
   "source": [
    "To create a metric for how the test scores have improved, we are subtracting the 2009 average score from each data point to define how much the average math and reading test scores have changed since 2009. We are storing this metric in a new column, \"READING_GROWTH\" and \"MATH_GROWTH\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2148248c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-03b7281690bf>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_avg['READING_GROWTH'] = np.NaN\n",
      "<ipython-input-6-03b7281690bf>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_avg['MATHEMATICS_GROWTH'] = np.NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>G04_A_A_READING</th>\n",
       "      <th>G04_A_A_MATHEMATICS</th>\n",
       "      <th>READING_GROWTH</th>\n",
       "      <th>MATHEMATICS_GROWTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2009</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>ALASKA</td>\n",
       "      <td>2009</td>\n",
       "      <td>211.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>2009</td>\n",
       "      <td>210.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>2009</td>\n",
       "      <td>216.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>2009</td>\n",
       "      <td>210.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          STATE  YEAR  G04_A_A_READING  G04_A_A_MATHEMATICS  READING_GROWTH  \\\n",
       "867     ALABAMA  2009            216.0                228.0             0.0   \n",
       "868      ALASKA  2009            211.0                237.0             0.0   \n",
       "869     ARIZONA  2009            210.0                230.0             0.0   \n",
       "870    ARKANSAS  2009            216.0                238.0             0.0   \n",
       "871  CALIFORNIA  2009            210.0                232.0             0.0   \n",
       "\n",
       "     MATHEMATICS_GROWTH  \n",
       "867                 0.0  \n",
       "868                 0.0  \n",
       "869                 0.0  \n",
       "870                 0.0  \n",
       "871                 0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_avg['READING_GROWTH'] = np.NaN\n",
    "\n",
    "def process_reading(row):\n",
    "    state = row['STATE']\n",
    "    new = state_avg.loc[state_avg['STATE'] == state]\n",
    "    new = new.loc[new['YEAR'] == 2009]\n",
    "    return new['G04_A_A_READING']\n",
    "\n",
    "for i, row in state_avg.iterrows():\n",
    "    state_avg.at[i, 'READING_GROWTH'] = row['G04_A_A_READING'] - process_reading(row)\n",
    "    \n",
    "state_avg['MATHEMATICS_GROWTH'] = np.NaN\n",
    "\n",
    "def process_reading(row):\n",
    "    state = row['STATE']\n",
    "    new = state_avg.loc[state_avg['STATE'] == state]\n",
    "    new = new.loc[new['YEAR'] == 2009]\n",
    "    return new['G04_A_A_MATHEMATICS']\n",
    "\n",
    "for i, row in state_avg.iterrows():\n",
    "    state_avg.at[i, 'MATHEMATICS_GROWTH'] = row['G04_A_A_MATHEMATICS'] - process_reading(row)\n",
    "    \n",
    "state_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eaca32",
   "metadata": {},
   "source": [
    "Now we have to split apart the dataset into a train and test dataset so that we can use the test dataset to determine how accurate our predictor is. We are going to predict the years 2017, 2018, and 2019 so we will use those rows as our test data and the rest as our train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e2379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = state_avg[state_avg['YEAR'] < 2017].dropna()\n",
    "test_data = state_avg[state_avg['YEAR'] >= 2017].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade5a9f",
   "metadata": {},
   "source": [
    "We can use Linear SVM from sklearn to make a regression model. We will make one for reading and one for mathematics. First we have to separate our independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf55c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_reading = []\n",
    "y_reading = []\n",
    "X_math = []\n",
    "y_math = []\n",
    "\n",
    "for i, row in train_data.iterrows():\n",
    "    add = [row['STATE'], row['YEAR']]\n",
    "    X_reading.append(add)\n",
    "    y_reading.append(row['READING_GROWTH'])\n",
    "    X_math.append(add)\n",
    "    y_math.append(row['MATHEMATICS_GROWTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4c606",
   "metadata": {},
   "source": [
    "We can use make_pipeline to to create a LinearSVM model and then fit the model to our X and y variables. Once the model is fit, we can predict the expected growth for each state and year for the years 2017, 2018, and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8421232",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ALABAMA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-154ea99f3541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmathematics_regr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreading_regr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reading\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_reading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmathematics_regr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_math\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_math\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[0mTransformer\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \"\"\"\n\u001b[1;32m--> 696\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    697\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ALABAMA'"
     ]
    }
   ],
   "source": [
    "#reading_regr = make_pipeline(StandardScaler(), LinearSVR(random_state=0, tol=1e-5))\n",
    "#mathematics_regr = make_pipeline(StandardScaler(), LinearSVR(random_state=0, tol=1e-5))\n",
    "\n",
    "#reading_regr.fit(X_reading, y_reading)\n",
    "#mathematics_regr.fit(X_math, y_math)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9013db",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bedd5",
   "metadata": {},
   "source": [
    "## Communication of Insights Attained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
